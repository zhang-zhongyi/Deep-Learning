{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/\n",
    "https://stackoverflow.com/questions/54262301/importerror-no-module-named-yolo-utils\n",
    "https://stackoverflow.com/questions/9822618/how-to-paste-source-code-to-vim-without-error-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/iArunava/YOLOv3-Object-Detection-with-OpenCV/blob/master/yolo_utils.py\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "def show_image(img):\n",
    "    cv.imshow(\"Image\", img)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "def draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels):\n",
    "    # If there are any detections\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            # Get the bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            \n",
    "            # Get the unique color for this class\n",
    "            color = [int(c) for c in colors[classids[i]]]\n",
    "\n",
    "            # Draw the bounding box rectangle and label on the image\n",
    "            cv.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "            text = \"{}: {:4f}\".format(labels[classids[i]], confidences[i])\n",
    "            cv.putText(img, text, (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_boxes_confidences_classids(outs, height, width, tconf):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classids = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            #print (detection)\n",
    "            #a = input('GO!')\n",
    "            \n",
    "            # Get the scores, classid, and the confidence of the prediction\n",
    "            scores = detection[5:]\n",
    "            classid = np.argmax(scores)\n",
    "            confidence = scores[classid]\n",
    "            \n",
    "            # Consider only the predictions that are above a certain confidence level\n",
    "            if confidence > tconf:\n",
    "                # TODO Check detection\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                centerX, centerY, bwidth, bheight = box.astype('int')\n",
    "\n",
    "                # Using the center x, y coordinates to derive the top\n",
    "                # and the left corner of the bounding box\n",
    "                x = int(centerX - (bwidth / 2))\n",
    "                y = int(centerY - (bheight / 2))\n",
    "\n",
    "                # Append to list\n",
    "                boxes.append([x, y, int(bwidth), int(bheight)])\n",
    "                confidences.append(float(confidence))\n",
    "                classids.append(classid)\n",
    "\n",
    "    return boxes, confidences, classids\n",
    "\n",
    "def infer_image(net, layer_names, height, width, img, colors, labels, FLAGS, \n",
    "            boxes=None, confidences=None, classids=None, idxs=None, infer=True):\n",
    "    \n",
    "    if infer:\n",
    "        # Contructing a blob from the input image\n",
    "        blob = cv.dnn.blobFromImage(img, 1 / 255.0, (416, 416), \n",
    "                        swapRB=True, crop=False)\n",
    "\n",
    "        # Perform a forward pass of the YOLO object detector\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Getting the outputs from the output layers\n",
    "        start = time.time()\n",
    "        outs = net.forward(layer_names)\n",
    "        end = time.time()\n",
    "\n",
    "        if FLAGS.show_time:\n",
    "            print (\"[INFO] YOLOv3 took {:6f} seconds\".format(end - start))\n",
    "\n",
    "        \n",
    "        # Generate the boxes, confidences, and classIDs\n",
    "        boxes, confidences, classids = generate_boxes_confidences_classids(outs, height, width, FLAGS.confidence)\n",
    "        \n",
    "        # Apply Non-Maxima Suppression to suppress overlapping bounding boxes\n",
    "        idxs = cv.dnn.NMSBoxes(boxes, confidences, FLAGS.confidence, FLAGS.threshold)\n",
    "\n",
    "    if boxes is None or confidences is None or idxs is None or classids is None:\n",
    "        raise '[ERROR] Required variables are set to None before drawing boxes on images.'\n",
    "        \n",
    "    # Draw labels and boxes on the image\n",
    "    img = draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels)\n",
    "\n",
    "    return img, boxes, confidences, classids, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-670b618725a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myolo_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_anchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_colors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myad2k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_yolo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myolo_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo_boxes_to_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_true_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yolo_utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
